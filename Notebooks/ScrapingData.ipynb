{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ScrapingData.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPswbcVOo5+HB0tqnZRN9h4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3t3wfw9S5wkq","executionInfo":{"status":"ok","timestamp":1651782477495,"user_tz":240,"elapsed":43667,"user":{"displayName":"Sarang Patil","userId":"01281672512836668061"}},"outputId":"32f3a34d-bbd7-4284-e40d-b41f182fcb42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.1.5-py3-none-any.whl (979 kB)\n","\u001b[K     |████████████████████████████████| 979 kB 5.2 MB/s \n","\u001b[?25hCollecting trio~=0.17\n","  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n","\u001b[K     |████████████████████████████████| 359 kB 20.2 MB/s \n","\u001b[?25hCollecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting urllib3[secure,socks]~=1.26\n","  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 53.1 MB/s \n","\u001b[?25hCollecting async-generator>=1.9\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n","Collecting sniffio\n","  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n","Collecting outcome\n","  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n","Collecting cryptography>=1.3.4\n","  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 42.9 MB/s \n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n","Collecting pyOpenSSL>=0.14\n","  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.2.0)\n","Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.5 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n","Collecting webdriver_manager\n","  Downloading webdriver_manager-3.5.4-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from webdriver_manager) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (2021.10.8)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->webdriver_manager) (3.0.4)\n","Installing collected packages: urllib3, webdriver-manager\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.9\n","    Uninstalling urllib3-1.26.9:\n","      Successfully uninstalled urllib3-1.26.9\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","selenium 4.1.5 requires urllib3[secure,socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed urllib3-1.25.11 webdriver-manager-3.5.4\n","Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,498 kB]\n","Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,734 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,272 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,168 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,954 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,001 kB]\n","Fetched 12.9 MB in 4s (3,508 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following packages were automatically installed and are no longer required:\n","  libnvidia-common-460 nsight-compute-2020.2.0\n","Use 'apt autoremove' to remove them.\n","The following additional packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n","Suggested packages:\n","  webaccounts-chromium-extension unity-chromium-extension\n","The following NEW packages will be installed:\n","  chromium-browser chromium-browser-l10n chromium-chromedriver\n","  chromium-codecs-ffmpeg-extra\n","0 upgraded, 4 newly installed, 0 to remove and 50 not upgraded.\n","Need to get 88.4 MB of archives.\n","After this operation, 297 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 100.0.4896.127-0ubuntu0.18.04.1 [1,142 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 100.0.4896.127-0ubuntu0.18.04.1 [77.6 MB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 100.0.4896.127-0ubuntu0.18.04.1 [4,496 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 100.0.4896.127-0ubuntu0.18.04.1 [5,190 kB]\n","Fetched 88.4 MB in 2s (48.0 MB/s)\n","Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n","(Reading database ... 155203 files and directories currently installed.)\n","Preparing to unpack .../chromium-codecs-ffmpeg-extra_100.0.4896.127-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-codecs-ffmpeg-extra (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser.\n","Preparing to unpack .../chromium-browser_100.0.4896.127-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-browser (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-browser-l10n.\n","Preparing to unpack .../chromium-browser-l10n_100.0.4896.127-0ubuntu0.18.04.1_all.deb ...\n","Unpacking chromium-browser-l10n (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Selecting previously unselected package chromium-chromedriver.\n","Preparing to unpack .../chromium-chromedriver_100.0.4896.127-0ubuntu0.18.04.1_amd64.deb ...\n","Unpacking chromium-chromedriver (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Setting up chromium-codecs-ffmpeg-extra (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser (100.0.4896.127-0ubuntu0.18.04.1) ...\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n","update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n","Setting up chromium-chromedriver (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Setting up chromium-browser-l10n (100.0.4896.127-0ubuntu0.18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"]}],"source":["!pip install selenium\n","!pip install webdriver_manager\n","!pip install -q jmd_imagescraper\n","!apt-get update\n","!apt install chromium-chromedriver\n","!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n","import sys\n","sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n","from selenium import webdriver\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')\n","chrome_options.add_argument(\"--window-size=1920x1080\")"]},{"cell_type":"markdown","source":["# Scraping Description and URLs"],"metadata":{"id":"LdMuDrO68gEn"}},{"cell_type":"code","source":["#importing required libraries\n","from selenium import webdriver\n","from selenium.webdriver.common.keys import Keys\n","from selenium.webdriver.chrome.service import Service\n","from webdriver_manager.chrome import ChromeDriverManager\n","from selenium.webdriver.common.by import By\n","from time import sleep\n","import pandas as pd"],"metadata":{"id":"Fu8c0j8w5z6D","executionInfo":{"status":"ok","timestamp":1651782477866,"user_tz":240,"elapsed":380,"user":{"displayName":"Sarang Patil","userId":"01281672512836668061"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#mounting google drive\n","from google.colab import drive \n","drive.mount('/content/gdrive')\n","df = pd.read_csv('/content/gdrive/MyDrive/DATA_690_NLP_Project_Recommender_System/Ujjwal/new_datasets/reviews_4.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-UGJDf5L5z3h","executionInfo":{"status":"ok","timestamp":1651782554128,"user_tz":240,"elapsed":17475,"user":{"displayName":"Sarang Patil","userId":"01281672512836668061"}},"outputId":"79b9cb03-014e-4e4d-a1bb-32b36e2ea67a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.neighbors import NearestNeighbors\n","import plotly.express as px\n","\n","#Grouping the dataset reviews on basis of name of the game\n","ProductReviewSummary = df.groupby(\"app_name\")[\"clean_review_text\"].apply(str)\n","\n","p = ProductReviewSummary.to_frame()\n","p.reset_index(inplace=True)\n","\n","#getting list of game ids in lit\n","lit = p.index.tolist()"],"metadata":{"id":"GKwTPlsf5zyK","executionInfo":{"status":"ok","timestamp":1651782632406,"user_tz":240,"elapsed":6424,"user":{"displayName":"Sarang Patil","userId":"01281672512836668061"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#designing a function that will scrape description and URLs with the help of \"Selenium webdriver\"\n","def get_desc_url(name):\n","    s = Service(ChromeDriverManager().install())\n","\n","    driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n","    driver.get('https://store.steampowered.com/')\n","    \n","    \n","    driver.find_element_by_xpath('//*[@id=\"store_nav_search_term\"]').send_keys(name)\n","    sleep(0.1)\n","    \n","    driver.find_element_by_xpath('/html/body/div[1]/div[7]/div[5]/div[1]/div[2]/div[4]/div/div/div/div[2]/div[2]/div/div[9]/div[1]/form/div/a/img').click()                          \n","    sleep(0.1)                    #/html/body/div[1]/div[7]/div[5]/div[1]/div[2]/div[4]/div/div/div/div[2]/div[2]/div/div[9]/div[1]/form/div/a/img\n","    \n","    driver.execute_script('document.cookie = \\\"birthtime=0; path=/; max-age=315360000\\\"')\n","    sleep(0.1)\n","\n","    try:\n","         driver.find_element_by_xpath('/html/body/div[1]/div[7]/div[5]/form/div[1]/div/div[1]/div[3]/div[2]/div[3]/a[1]/div[2]/div[1]/span').click()\n","    except:\n","        sleep(0.1)\n","\n","    try:\n","        driver.find_element_by_xpath('/html/body/div[1]/div[7]/div[5]/form/div[1]/div/div[1]/div[3]/div/div[3]/a[1]/div[2]/div[1]/span').click()\n","    except:\n","        sleep(0.1)\n","\n","    gre = ''\n","\n","    try:\n","         gre = driver.find_element_by_xpath('/html/body/div[1]/div[7]/div[5]/div[1]/div[3]/div[1]/div[3]/div[1]/div[2]/div[1]/div/div[2]').text\n","    except:\n","        sleep(0.1)\n","\n","    try:\n","        gre = driver.find_element_by_xpath('/html/body/div[1]/div[7]/div[5]/div[1]/div[3]/div[1]/div[4]/div[1]/div[2]/div[1]/div/div[2]').text\n","    except:\n","        sleep(0.1)\n","        \n","    url = driver.current_url\n","        \n","    return gre, url"],"metadata":{"id":"HhgIEEOl75m9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#the scraped data will be collected into list which will later be converted into a dataset by tupling the relevant Descriptions, URLs and Game Names.\n","des = []\n","url = []\n","j=0\n","for i in lit:\n","      d, u = get_desc_url(i)\n","      des.append(d)\n","      url.append(u)\n","scrapedf = pd.DataFrame(list(zip(des, url, lit)), columns=['Description','URL', 'GameName'])\n","scrapedf.to_csv('Desc.csv')"],"metadata":{"id":"czo8SiFK5zsM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scraping Images of each game"],"metadata":{"id":"N8uvKZbd8jjl"}},{"cell_type":"code","source":["#below code will scrape 3 images of each and every game present in the dataset and save those in appropriate folder name designated to game IDs\n","from pathlib import Path\n","root = Path().cwd()/\"Images\"\n","from jmd_imagescraper.core import *\n","\n","for i in range(0, len(p)):\n","  duckduckgo_search(root, str(i), p['app_name'][i]+' game', max_results=3)"],"metadata":{"id":"xu1aLi2q7FPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saving the images in drive\n","!cp -av '/content/Images' '/content/gdrive/MyDrive/690 Project/Sarang/Images' "],"metadata":{"id":"mGxGcCpp7One"},"execution_count":null,"outputs":[]}]}